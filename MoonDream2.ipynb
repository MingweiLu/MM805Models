{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (4.40.0)\n",
      "Requirement already satisfied: timm in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (0.9.16)\n",
      "Requirement already satisfied: einops in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: filelock in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from transformers) (2024.4.16)\n",
      "Requirement already satisfied: requests in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: torch in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from timm) (2.2.2)\n",
      "Requirement already satisfied: torchvision in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from timm) (0.17.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from torch->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from torch->timm) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from torch->timm) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from torch->timm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from torch->timm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from torch->timm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from torch->timm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from torch->timm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from torch->timm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from torch->timm) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from torch->timm) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.4.127)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from torchvision->timm) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/mingwei/anaconda3/envs/MoonDream/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers timm einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_colwidth', 256)\n",
    "import re\n",
    "import numpy as np \n",
    "# from https://www.kaggle.com/code/nilaychauhan/fine-tune-gemma-models-in-keras-using-lora\n",
    "\n",
    "# # Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n",
    "!pip install -q -U keras-nlp\n",
    "!pip install -q -U keras>=3\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n",
    "# Avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U keras-nlp\n",
    "!pip install -q -U keras>=3\n",
    "!export KERAS_BACKEND=\"jax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export XLA_PYTHON_CLIENT_MEM_FRACTION=1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "#keras.mixed_precision.set_global_policy('mixed_bfloat16') ## this gives out of memory error\n",
    "keras.config.set_floatx(\"bfloat16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_instruct_2b_en\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from PIL import Image\n",
    "import torch\n",
    "# Check for CUDA availability and set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "model_id = \"vikhyatk/moondream2\"\n",
    "revision = \"2024-03-06\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, revision=revision).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glass\n"
     ]
    }
   ],
   "source": [
    "prompt= \"\"\n",
    "def classific(path):\n",
    "    global prompt\n",
    "    image = Image.open(path)\n",
    "    enc_image = model.encode_image(image)\n",
    "    category= model.answer_question(enc_image, \"\"\" accurately categorize image name among the following classes:\n",
    "    battery, biological , glass ,cardboard, clothes, metal , paper, plastic , shoes , edible_waste.\n",
    "\n",
    "    #.And show the category in single word and donot give any explanation . \"\"\", tokenizer)\n",
    "    print(category)\n",
    "\n",
    "    if category == \"Glass\":\n",
    "        prompt = \"\"\"Please provide detailed information on the proper disposal methods for glass waste, including recycling processes and environmentally friendly disposal techniques. \n",
    "        Additionally, suggest practical strategies and initiatives that individuals and communities can implement to reduce their carbon footprint. This may include tips for energy conservation, sustainable transportation options, waste reduction practices, and other eco-friendly lifestyle changes.\n",
    "\"\"\"\n",
    "    elif category == \"Paper\":\n",
    "        prompt = \"\"\"Please provide detailed information on the proper disposal methods for Paper waste, including recycling processes and environmentally friendly disposal techniques.\n",
    "\n",
    "Additionally, suggest practical strategies and initiatives that individuals and communities can implement to reduce their carbon footprint. This may include tips for energy conservation, sustainable transportation options, waste reduction practices, and other eco-friendly lifestyle changes.\n",
    "\"\"\"   \n",
    "    elif category == \"Cardboard\":\n",
    "        prompt = \"\"\"Please provide detailed information on the proper disposal methods for Cardboard waste, including recycling processes and environmentally friendly disposal techniques.\n",
    "\n",
    "Additionally, suggest practical strategies and initiatives that individuals and communities can implement to reduce their carbon footprint. This may include tips for energy conservation, sustainable transportation options, waste reduction practices, and other eco-friendly lifestyle changes.\n",
    "\"\"\" \n",
    "    elif category == \"Plastic\":\n",
    "        prompt = \"\"\"Please provide detailed information on the proper disposal methods for Plastic waste, including recycling processes and environmentally friendly disposal techniques.\n",
    "\n",
    "Additionally, suggest practical strategies and initiatives that individuals and communities can implement to reduce their carbon footprint. This may include tips for energy conservation, sustainable transportation options, waste reduction practices, and other eco-friendly lifestyle changes.\n",
    "\"\"\"\n",
    "    elif category == \"Metal\":\n",
    "        prompt = \"\"\"Please provide detailed information on the proper disposal methods for Metal waste, including recycling processes and environmentally friendly disposal techniques.\n",
    "\n",
    "Additionally, suggest practical strategies and initiatives that individuals and communities can implement to reduce their carbon footprint. This may include tips for energy conservation, sustainable transportation options, waste reduction practices, and other eco-friendly lifestyle changes.\n",
    "\"\"\"  \n",
    "    else:\n",
    "        prompt = \"Please provide information about recycling.\"\n",
    "\n",
    "# Print the prompt\n",
    " \n",
    "    \n",
    "# Put you inmagd\n",
    "classific(\"garbage classification/Garbage classification/glass/glass10.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glass\n",
      "cardboard\n",
      "metal\n",
      "paper\n",
      "plastic\n",
      "Accuracy for glass: 0.99\n",
      "Accuracy for cardboard: 0.84\n",
      "Accuracy for metal: 0.40\n",
      "Accuracy for paper: 0.80\n",
      "Accuracy for plastic: 0.68\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Check for CUDA availability and set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_id = \"vikhyatk/moondream2\"\n",
    "revision = \"2024-03-06\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, revision=revision).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)\n",
    "\n",
    "def classific(path):\n",
    "    image = Image.open(path).convert('RGB')  # Ensure image is in RGB\n",
    "    enc_image = model.encode_image(image).to(device)  # Move encoded image to GPU\n",
    "    category = model.answer_question(enc_image, \"\"\"\n",
    "        accurately categorize image name among the following classes:\n",
    "        glass, cardboard, metal, paper, plastic.\n",
    "\n",
    "        #.And show the category in single word and do not give any explanation.\n",
    "    \"\"\", tokenizer)\n",
    "    return category.strip().lower()  # Return category as lowercase for uniformity\n",
    "\n",
    "# Define the directories and materials\n",
    "root_dir = 'garbage classification/Garbage classification'\n",
    "materials = [\"glass\", \"cardboard\", \"metal\", \"paper\", \"plastic\"]\n",
    "accuracy_dict = {material: {'correct': 0, 'total': 0} for material in materials}\n",
    "\n",
    "# Iterate over each material directory\n",
    "for material in materials:\n",
    "    print(material)\n",
    "    directory = os.path.join(root_dir, material)\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            predicted_category = classific(image_path)\n",
    "            # Increment counts\n",
    "            accuracy_dict[material]['total'] += 1\n",
    "            if material == predicted_category:\n",
    "                accuracy_dict[material]['correct'] += 1\n",
    "\n",
    "# Calculate and print accuracy for each material\n",
    "for material, counts in accuracy_dict.items():\n",
    "    if counts['total'] > 0:\n",
    "        accuracy = counts['correct'] / counts['total']\n",
    "        print(f\"Accuracy for {material}: {accuracy:.2f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
